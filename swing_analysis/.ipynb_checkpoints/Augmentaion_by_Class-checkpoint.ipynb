{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.naive_bayes as nb\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import LSTM,Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense \n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout,Input,Dense,Activation,Flatten,SeparableConv2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn.utils import resample\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load:\n",
    "    def __init__(self):\n",
    "        self.file_name_dir = []\n",
    "        self.total_data = []\n",
    "        self.total_label = []\n",
    "    \n",
    "    def load_file(self,dir_location):\n",
    "        print('now loading_file (location : ' + dir_location + ') ... \\n')\n",
    "        \n",
    "        for root,dirs,files in os.walk(dir_location):\n",
    "            for fname in files:\n",
    "                full_fname = os.path.join(root,fname)\n",
    "                self.file_name_dir.append(full_fname)\n",
    "        \n",
    "        print('make file list complete')\n",
    "    \n",
    "    def make_DataFrame(self,tar_li,p_n):\n",
    "        for file_name in tqdm(self.file_name_dir):\n",
    "            sp = file_name.split('/')\n",
    "            tmp_label = sp[1]\n",
    "            d = open(file_name,'r',encoding='UTF8').read()\n",
    "            data = d.split('\\n')\n",
    "            data.pop(0) # remove trash data header\n",
    "            index = data.pop(0)\n",
    "            tmp_real_data = []\n",
    "            for dat_num in range(len(data)):\n",
    "                if data[dat_num] == '':\n",
    "                    continue\n",
    "                tmp_real_data.append(data[dat_num].split(','))\n",
    "            \n",
    "            df = pd.DataFrame(tmp_real_data)\n",
    "            index_li = index.split(',')\n",
    "            df.columns = index_li\n",
    "            \n",
    "            #now change str to float\n",
    "            \n",
    "            for y in index_li:\n",
    "                df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "            \n",
    "            tmp_li = []\n",
    "            for i in range(len(df)):\n",
    "                tmp = []\n",
    "                for j in tar_li:\n",
    "                    tmp.append((df[j][i]/1000)**p_n)\n",
    "                tmp_li.append(tmp)\n",
    "            \n",
    "            self.total_data.append(tmp_li)\n",
    "            self.total_label.append(tmp_label)\n",
    "        print('make total_data finish.....')\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def return_data(self):\n",
    "        return self.total_data , self.total_label\n",
    "\n",
    "            \n",
    "\n",
    "         \n",
    "class Train_model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.encoder = LabelEncoder()\n",
    "        self.enc_label = 0\n",
    "        \n",
    "        self.total_data = 0\n",
    "        self.total_label = 0\n",
    "        \n",
    "        self.x_train = 0\n",
    "        self.y_train = 0\n",
    "        self.x_test = 0\n",
    "        self.y_test = 0\n",
    "        \n",
    "        self.earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "        \n",
    "        #model list\n",
    "        self.lstm = 0\n",
    "        self.svm = 0\n",
    "        self.xgboost = 0\n",
    "        self.nb = 0\n",
    "        self.rf =0\n",
    "        self.knn = 0\n",
    "        \n",
    "        #sample prediction\n",
    "        self.sample_data = 0\n",
    "        self.sample_label = 0\n",
    "        \n",
    "    def get_enc(self):\n",
    "        self.enc_label = self.encoder.fit_transform(self.total_label)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def make_arr(self):\n",
    "        self.total_data = np.array(self.total_data)\n",
    "        self.enc_label =np.array(self.enc_label)\n",
    "        \n",
    "    def Data_Augmentation(self,nu):\n",
    "        \n",
    "        #Data Augmentation is very optional Function\n",
    "        \n",
    "        tmp_li = [0]\n",
    "        for x in range(len(self.enc_label)-1):\n",
    "            if self.enc_label[x] != self.enc_label[x+1]:\n",
    "                tmp_li.append(x)\n",
    "        tmp_li.append(len(self.enc_label)-1)\n",
    "        print('Augmentation Data index is : ',tmp_li)\n",
    "        \n",
    "        div_data = []\n",
    "        div_label = []\n",
    "        for x in range(len(tmp_li)-1):\n",
    "            div_tmp =[]\n",
    "            div_la = []\n",
    "            for y in range(tmp_li[x]+1,tmp_li[x+1]+1):\n",
    "                div_tmp.append(self.total_data[y])\n",
    "                div_la.append(self.enc_label[y])\n",
    "            div_data.append(div_tmp)\n",
    "            div_label.append(div_la)\n",
    "        \n",
    "        \n",
    "        boot = []\n",
    "        label = []\n",
    "        t_li = [5,1,7,6,0,4,2,3]\n",
    "        for x in range(len(div_data)):\n",
    "            tmp = resample(div_data[x],replace=True,n_samples = nu,random_state=1)\n",
    "            boot+=tmp\n",
    "            label += list(t_li[x] for i in range(nu))\n",
    "        \n",
    "        boot = np.array(boot)\n",
    "        label = np.array(label)\n",
    "        \n",
    "        self.total_data = np.append(self.total_data,boot,axis=0)\n",
    "        self.enc_label = np.append(self.enc_label,label,axis=0)\n",
    "        \n",
    "    def divide_dataset(self,mode):\n",
    "        \n",
    "        if mode == 'lstm':\n",
    "            self.x_train,self.x_test,self.y_train,self.y_test = train_test_split(self.total_data,self.enc_label,test_size=0.2,random_state=0)\n",
    "\n",
    "        else:\n",
    "            self.x_train,self.x_test,self.y_train,self.y_test = train_test_split(self.total_data,self.enc_label,test_size=0.2,random_state=0)\n",
    "            nsamples,nx,ny = self.x_train.shape\n",
    "            self.x_train = self.x_train.reshape((nsamples,nx*ny))\n",
    "            nsamples,nx,ny = self.x_test.shape\n",
    "            self.x_test = self.x_test.reshape((nsamples,nx*ny))\n",
    "        \n",
    "    def model_create_train(self,mode):\n",
    "        if mode == 'lstm':\n",
    "            with tf.device('/GPU:0'):\n",
    "                model = Sequential() # Sequeatial Model \n",
    "                model.add(LSTM(180, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(Conv1D(128,\n",
    "                                 2,\n",
    "                                 padding='valid',\n",
    "                                 activation='relu',\n",
    "                                 strides=1))\n",
    "                model.add(MaxPooling1D(pool_size=4))\n",
    "                model.add(LSTM(128))\n",
    "                model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "                # 3. 모델 학습과정 설정하기\n",
    "                model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "                hist = model.fit(self.x_train, self.y_train, epochs=100, batch_size=256,callbacks=[self.earlystopping] ,validation_data=(self.x_test, self.y_test))\n",
    "                model.save('model_x.h5')\n",
    "                model.save_weights('model_x_weights.h5')\n",
    "            self.lstm = model\n",
    "            \n",
    "        elif mode=='svm':\n",
    "            #####here to change####\n",
    "            ######################################################################\n",
    "\n",
    "            best_score = 0\n",
    "\n",
    "            for gamma in [0.001,0.01,0.1,1,10]:\n",
    "                for C in [0.001,0.01,0.1,1,10]:\n",
    "                    for kernel in ['linear','rbf','poly']:\n",
    "                        tmp_model = svm.SVC(kernel=kernel,gamma=gamma,C=C)\n",
    "                        scores = cross_val_score(tmp_model,self.x_train,self.y_train,cv=10,n_jobs=-1)\n",
    "                        score = np.mean(scores)\n",
    "\n",
    "                        if score>best_score:\n",
    "\n",
    "                            best_score = score\n",
    "                            best_parameter = {'kernel':kernel,'gamma':gamma,'C':C}\n",
    "                            print('best_parameter is change : ',best_parameter)\n",
    "                        else:\n",
    "                            print('remain :',best_parameter)\n",
    "            mod = svm.SVC(**best_parameter)\n",
    "            \n",
    "\n",
    "            ######################################################################\n",
    "            \n",
    "            predict_model = mod.fit(self.x_train,self.y_train)\n",
    "            print('fitting ',mode,' is complete...')\n",
    "            print(mode,'score is :',predict_model.score(self.x_test,self.y_test))\n",
    "\n",
    "            prediction = predict_model.predict(self.x_test)\n",
    "            self.svm = mod\n",
    "        \n",
    "        elif mode=='xgboost':\n",
    "            #####here to change####\n",
    "            ######################################################################\n",
    "\n",
    "            space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "                    'gamma': hp.uniform ('gamma', 1,9),\n",
    "                    'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "                    'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "                    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "                    'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "                    'n_estimators': 180,\n",
    "                    'seed': 0\n",
    "                }\n",
    "\n",
    "            mod =xgb.XGBClassifier(\n",
    "                                n_estimators =space['n_estimators'], max_depth = space['max_depth'], gamma = space['gamma'],\n",
    "                                reg_alpha = space['reg_alpha'],min_child_weight=space['min_child_weight'],\n",
    "                                colsample_bytree=space['colsample_bytree'])\n",
    "\n",
    "            \n",
    "\n",
    "            ######################################################################\n",
    "            \n",
    "            predict_model = mod.fit(self.x_train,self.y_train)\n",
    "            print('fitting ',mode,' is complete...')\n",
    "            print(mode,'score is :',predict_model.score(self.x_test,self.y_test))\n",
    "\n",
    "            prediction = predict_model.predict(self.x_test)\n",
    "            self.xgboost = mod\n",
    "        \n",
    "        elif mode=='nb':\n",
    "            #####here to change####\n",
    "            ######################################################################\n",
    "\n",
    "            mod = GaussianNB()\n",
    "\n",
    "            ######################################################################\n",
    "            \n",
    "            predict_model = mod.fit(self.x_train,self.y_train)\n",
    "            print('fitting ',mode,' is complete...')\n",
    "            print(mode,'score is :',predict_model.score(self.x_test,self.y_test))\n",
    "\n",
    "            prediction = predict_model.predict(self.x_test)\n",
    "            self.nb = mod\n",
    "        \n",
    "        \n",
    "        elif mode=='rf':\n",
    "            #####here to change####\n",
    "            ######################################################################\n",
    "            \n",
    "            rfc=RandomForestClassifier(random_state=42)\n",
    "            param_grid = { \n",
    "                'n_estimators': [10,15,20,30,40,50,100],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'max_depth' : [3,4,5,6,7,8,9],\n",
    "                'criterion' :['gini', 'entropy']\n",
    "            }\n",
    "\n",
    "            mod = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10,n_jobs=-1)\n",
    "\n",
    "            \n",
    "            ######################################################################\n",
    "            \n",
    "            predict_model = mod.fit(self.x_train,self.y_train)\n",
    "            print('fitting ',mode,' is complete...')\n",
    "            print(mode,'score is :',predict_model.score(self.x_test,self.y_test))\n",
    "\n",
    "            prediction = predict_model.predict(self.x_test)\n",
    "            self.rf = mod\n",
    "        \n",
    "        elif mode=='knn':\n",
    "            #####here to change####\n",
    "            ######################################################################\n",
    "            \n",
    "            leaf_size = list(range(1,30))\n",
    "            n_neighbors = list(range(1,8))\n",
    "            p=[1,2]\n",
    "\n",
    "            hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "            knn = KNeighborsClassifier()\n",
    "\n",
    "            mod = GridSearchCV(knn, hyperparameters, cv=10, n_jobs=-1)\n",
    "\n",
    "            \n",
    "            ######################################################################\n",
    "            \n",
    "            predict_model = mod.fit(self.x_train,self.y_train)\n",
    "            print('fitting ',mode,' is complete...')\n",
    "            print(mode,'score is :',predict_model.score(self.x_test,self.y_test))\n",
    "\n",
    "            prediction = predict_model.predict(self.x_test)\n",
    "            self.knn = mod\n",
    "        \n",
    "    \n",
    "    def prediction(self,input_axis,mode,p_n):\n",
    "        p = load()\n",
    "        p.load_file('test_data')\n",
    "        p.make_DataFrame(input_axis,p_n)\n",
    "        self.sample_data , self.sample_label = p.return_data()\n",
    "        \n",
    "        if mode == 'lstm':\n",
    "            self.sample_data = np.array(self.sample_data)\n",
    "            sample_pred = self.lstm.predict(self.sample_data)\n",
    "            sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "            lab = self.encoder.inverse_transform(sample_pred)\n",
    "            \n",
    "            hit = 0\n",
    "            miss = 0\n",
    "            answer=[]\n",
    "            print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "            for x in range(len(lab)):\n",
    "                if lab[x] == self.sample_label[x]:\n",
    "                    hit+=1\n",
    "                    answer.append(lab[x])\n",
    "                else:\n",
    "                    miss+=1\n",
    "                    print(self.sample_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "\n",
    "            print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))\n",
    "        \n",
    "        else:\n",
    "            model_list = ['svm','knn','rf','nb','xgboost']\n",
    "            match_list = [self.svm , self.knn , self.rf , self.nb , self.xgboost]\n",
    "            \n",
    "            for x in range(len(model_list)):\n",
    "                if model_list[x] == mode:\n",
    "                    mod = match_list[x]\n",
    "                    print(mode + 'model match complete.....')\n",
    "                \n",
    "            self.sample_data = np.array(self.sample_data)\n",
    "            nsamples , nx , ny = self.sample_data.shape\n",
    "            sample = self.sample_data.reshape((nsamples,nx*ny))\n",
    "            sample_pred = mod.predict(sample)\n",
    "            lab = self.encoder.inverse_transform(sample_pred)\n",
    "            \n",
    "            hit = 0\n",
    "            miss = 0\n",
    "            answer=[]\n",
    "            print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "            for x in range(len(lab)):\n",
    "                if lab[x] == self.sample_label[x]:\n",
    "                    hit+=1\n",
    "                    answer.append(lab[x])\n",
    "                else:\n",
    "                    miss+=1\n",
    "                    print(self.sample_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "\n",
    "            print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))\n",
    "            \n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IO(tar_dir,input_axis,p_n):\n",
    "    total_dat = []\n",
    "    total_lab = []\n",
    "    v = load()\n",
    "    v.load_file(tar_dir)\n",
    "    v.make_DataFrame(input_axis,p_n)\n",
    "    total_dat,total_lab = v.return_data()\n",
    "    return total_dat , total_lab\n",
    "\n",
    "def pipline(total_data,total_label,input_axis,mode,p_n,aug):\n",
    "    t = Train_model()\n",
    "    t.total_data = total_data\n",
    "    t.total_label = total_label\n",
    "    t.get_enc()\n",
    "    t.make_arr()\n",
    "    if aug != 0:\n",
    "        t.Data_Augmentation(5000)\n",
    "    t.divide_dataset(mode)\n",
    "    t.model_create_train(mode)\n",
    "    t.prediction(input_axis,mode,p_n)\n",
    "\n",
    "    \n",
    "def prac_machine(tar_dir,input_axis,mode_name,power,is_aug):\n",
    "    total_data = []\n",
    "    total_label = []\n",
    "    print('Dir : '+tar_dir+'\\nthis ML model name is '+mode_name+'\\npower : '+str(power),'\\n\\n\\n')\n",
    "    total_data,total_label = IO(tar_dir,input_axis,power)\n",
    "    pipline(total_data,total_label,input_axis,mode_name,power,is_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/12331 [00:00<01:12, 170.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir : swing\n",
      "this ML model name is lstm\n",
      "power : 4 \n",
      "\n",
      "\n",
      "\n",
      "now loading_file (location : swing) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 171.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "Augmentation Data index is :  [0, 1838, 3407, 5041, 6741, 8170, 9491, 10885, 12330]\n",
      "Train on 41864 samples, validate on 10467 samples\n",
      "Epoch 1/100\n",
      "41864/41864 [==============================] - 11s 251us/sample - loss: 0.4248 - acc: 0.8483 - val_loss: 0.1807 - val_acc: 0.9353\n",
      "Epoch 2/100\n",
      "41864/41864 [==============================] - 10s 231us/sample - loss: 0.1298 - acc: 0.9560 - val_loss: 0.1063 - val_acc: 0.9636\n",
      "Epoch 3/100\n",
      "41864/41864 [==============================] - 10s 231us/sample - loss: 0.0797 - acc: 0.9748 - val_loss: 0.0628 - val_acc: 0.9809\n",
      "Epoch 4/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0587 - acc: 0.9815 - val_loss: 0.0494 - val_acc: 0.9831\n",
      "Epoch 5/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0431 - acc: 0.9866 - val_loss: 0.0465 - val_acc: 0.9838\n",
      "Epoch 6/100\n",
      "41864/41864 [==============================] - 10s 231us/sample - loss: 0.0322 - acc: 0.9903 - val_loss: 0.0296 - val_acc: 0.9916\n",
      "Epoch 7/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0252 - acc: 0.9923 - val_loss: 0.0358 - val_acc: 0.9872\n",
      "Epoch 8/100\n",
      "41864/41864 [==============================] - 10s 231us/sample - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0340 - val_acc: 0.9886\n",
      "Epoch 9/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0225 - acc: 0.9927 - val_loss: 0.0259 - val_acc: 0.9927\n",
      "Epoch 10/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0155 - val_acc: 0.9950\n",
      "Epoch 11/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 0.0208 - acc: 0.9940 - val_loss: 0.0294 - val_acc: 0.9910\n",
      "Epoch 12/100\n",
      "41864/41864 [==============================] - 10s 234us/sample - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0143 - val_acc: 0.9955\n",
      "Epoch 13/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 0.0154 - acc: 0.9948 - val_loss: 0.0146 - val_acc: 0.9953\n",
      "Epoch 14/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0170 - val_acc: 0.9949\n",
      "Epoch 15/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0086 - val_acc: 0.9968\n",
      "Epoch 16/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9948\n",
      "Epoch 17/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0210 - val_acc: 0.9939\n",
      "Epoch 18/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0084 - acc: 0.9976 - val_loss: 0.0178 - val_acc: 0.9948\n",
      "Epoch 19/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0273 - val_acc: 0.9913\n",
      "Epoch 20/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0131 - acc: 0.9962 - val_loss: 0.0120 - val_acc: 0.9969\n",
      "Epoch 21/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0102 - val_acc: 0.9974\n",
      "Epoch 22/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0248 - val_acc: 0.9931\n",
      "Epoch 23/100\n",
      "41864/41864 [==============================] - 10s 234us/sample - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0114 - val_acc: 0.9970\n",
      "Epoch 24/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0057 - val_acc: 0.9987\n",
      "Epoch 25/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0109 - val_acc: 0.9968\n",
      "Epoch 26/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0086 - val_acc: 0.9969\n",
      "Epoch 27/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0099 - acc: 0.9973 - val_loss: 0.0069 - val_acc: 0.9987\n",
      "Epoch 28/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0100 - val_acc: 0.9975\n",
      "Epoch 29/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9988\n",
      "Epoch 30/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 9.0678e-04 - acc: 0.9997 - val_loss: 0.0094 - val_acc: 0.9977\n",
      "Epoch 31/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 7.2990e-04 - acc: 0.9999 - val_loss: 0.0043 - val_acc: 0.9989\n",
      "Epoch 32/100\n",
      "41864/41864 [==============================] - 10s 234us/sample - loss: 1.2242e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9989\n",
      "Epoch 33/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 8.9973e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9989\n",
      "Epoch 34/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 7.3191e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9989\n",
      "Epoch 35/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 6.5174e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Epoch 36/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 5.2254e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Epoch 37/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 4.6695e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9989\n",
      "Epoch 38/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 4.2149e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Epoch 39/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 3.8070e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Epoch 40/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 3.3508e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Epoch 41/100\n",
      "41864/41864 [==============================] - 10s 232us/sample - loss: 2.9303e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Epoch 42/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 2.6807e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Epoch 43/100\n",
      "41864/41864 [==============================] - 10s 233us/sample - loss: 2.4345e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 17/87 [00:00<00:00, 165.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading_file (location : test_data) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 172.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/12331 [00:00<01:10, 173.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_smash  -->  fo_cut         err_index number :  84\n",
      "hit:  86  miss :  1 percent :  98.85057471264368\n",
      "Dir : swing\n",
      "this ML model name is xgboost\n",
      "power : 4 \n",
      "\n",
      "\n",
      "\n",
      "now loading_file (location : swing) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 171.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/younghwan/.local/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation Data index is :  [0, 1838, 3407, 5041, 6741, 8170, 9491, 10885, 12330]\n",
      "[13:23:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 14/87 [00:00<00:00, 131.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting  xgboost  is complete...\n",
      "xgboost score is : 0.9988535396961881\n",
      "now loading_file (location : test_data) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 157.39it/s]\n",
      "  0%|          | 0/12331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "xgboostmodel match complete.....\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "hit:  87  miss :  0 percent :  100.0\n",
      "Dir : swing\n",
      "this ML model name is nb\n",
      "power : 4 \n",
      "\n",
      "\n",
      "\n",
      "now loading_file (location : swing) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 172.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 17/87 [00:00<00:00, 164.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation Data index is :  [0, 1838, 3407, 5041, 6741, 8170, 9491, 10885, 12330]\n",
      "fitting  nb  is complete...\n",
      "nb score is : 0.5419891086271138\n",
      "now loading_file (location : test_data) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 169.96it/s]\n",
      "  0%|          | 0/12331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "nbmodel match complete.....\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "fo_drive  -->  back_drive         err_index number :  0\n",
      "fo_drive  -->  back_drive         err_index number :  1\n",
      "fo_drive  -->  back_drive         err_index number :  2\n",
      "fo_drive  -->  back_drive         err_index number :  3\n",
      "fo_drive  -->  back_drive         err_index number :  4\n",
      "fo_drive  -->  fo_smash         err_index number :  5\n",
      "fo_drive  -->  back_drive         err_index number :  6\n",
      "fo_drive  -->  back_drive         err_index number :  7\n",
      "fo_drive  -->  back_drive         err_index number :  8\n",
      "fo_drive  -->  back_cut         err_index number :  9\n",
      "fo_drive  -->  back_drive         err_index number :  10\n",
      "fo_drive  -->  back_drive         err_index number :  11\n",
      "fo_drive  -->  back_short         err_index number :  12\n",
      "back_drive  -->  fo_cut         err_index number :  13\n",
      "back_drive  -->  back_cut         err_index number :  16\n",
      "back_drive  -->  back_cut         err_index number :  18\n",
      "back_drive  -->  back_smash         err_index number :  20\n",
      "back_drive  -->  back_smash         err_index number :  21\n",
      "fo_smash  -->  back_cut         err_index number :  23\n",
      "fo_short  -->  back_cut         err_index number :  33\n",
      "fo_short  -->  back_cut         err_index number :  34\n",
      "fo_short  -->  back_cut         err_index number :  35\n",
      "fo_short  -->  back_cut         err_index number :  36\n",
      "fo_short  -->  back_cut         err_index number :  37\n",
      "fo_short  -->  back_cut         err_index number :  38\n",
      "fo_short  -->  back_cut         err_index number :  39\n",
      "fo_short  -->  back_cut         err_index number :  40\n",
      "fo_short  -->  back_cut         err_index number :  41\n",
      "fo_short  -->  back_cut         err_index number :  42\n",
      "back_short  -->  back_cut         err_index number :  63\n",
      "back_short  -->  back_cut         err_index number :  66\n",
      "back_short  -->  fo_cut         err_index number :  69\n",
      "back_smash  -->  back_drive         err_index number :  73\n",
      "back_smash  -->  back_drive         err_index number :  76\n",
      "back_smash  -->  back_drive         err_index number :  77\n",
      "back_smash  -->  back_short         err_index number :  78\n",
      "back_smash  -->  back_short         err_index number :  79\n",
      "back_smash  -->  back_short         err_index number :  80\n",
      "back_smash  -->  back_short         err_index number :  81\n",
      "back_smash  -->  back_short         err_index number :  83\n",
      "back_smash  -->  fo_cut         err_index number :  84\n",
      "back_smash  -->  back_drive         err_index number :  85\n",
      "back_smash  -->  back_drive         err_index number :  86\n",
      "hit:  44  miss :  43 percent :  50.57471264367816\n",
      "Dir : swing\n",
      "this ML model name is rf\n",
      "power : 4 \n",
      "\n",
      "\n",
      "\n",
      "now loading_file (location : swing) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 172.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "Augmentation Data index is :  [0, 1838, 3407, 5041, 6741, 8170, 9491, 10885, 12330]\n",
      "fitting  rf  is complete...\n",
      "rf score is : 0.9808923282698003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 17/87 [00:00<00:00, 169.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading_file (location : test_data) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 170.15it/s]\n",
      "  0%|          | 0/12331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "rfmodel match complete.....\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "fo_drive  -->  back_short         err_index number :  12\n",
      "back_short  -->  back_smash         err_index number :  65\n",
      "back_smash  -->  fo_cut         err_index number :  84\n",
      "hit:  84  miss :  3 percent :  96.55172413793103\n",
      "Dir : swing\n",
      "this ML model name is knn\n",
      "power : 4 \n",
      "\n",
      "\n",
      "\n",
      "now loading_file (location : swing) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 172.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "Augmentation Data index is :  [0, 1838, 3407, 5041, 6741, 8170, 9491, 10885, 12330]\n",
      "fitting  knn  is complete...\n",
      "knn score is : 0.995796312219356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 18/87 [00:00<00:00, 175.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading_file (location : test_data) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 174.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "knnmodel match complete.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_drive  -->  back_smash         err_index number :  15\n",
      "back_drive  -->  back_smash         err_index number :  18\n",
      "back_drive  -->  back_smash         err_index number :  19\n",
      "back_drive  -->  back_smash         err_index number :  21\n",
      "back_drive  -->  back_smash         err_index number :  22\n",
      "fo_smash  -->  fo_drive         err_index number :  24\n",
      "fo_smash  -->  fo_drive         err_index number :  25\n",
      "back_cut  -->  fo_cut         err_index number :  43\n",
      "back_smash  -->  fo_cut         err_index number :  78\n",
      "back_smash  -->  fo_short         err_index number :  84\n",
      "hit:  77  miss :  10 percent :  88.50574712643679\n",
      "Dir : swing\n",
      "this ML model name is svm\n",
      "power : 4 \n",
      "\n",
      "\n",
      "\n",
      "now loading_file (location : swing) ... \n",
      "\n",
      "make file list complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 172.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make total_data finish.....\n",
      "Augmentation Data index is :  [0, 1838, 3407, 5041, 6741, 8170, 9491, 10885, 12330]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-41583106ad75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmode_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprac_machine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-77594f975764>\u001b[0m in \u001b[0;36mprac_machine\u001b[0;34m(tar_dir, input_axis, mode_name, power, is_aug)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dir : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtar_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\nthis ML model name is '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmode_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\npower : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtotal_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mpipline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-77594f975764>\u001b[0m in \u001b[0;36mpipline\u001b[0;34m(total_data, total_label, input_axis, mode, p_n, aug)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData_Augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_create_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-79a7b39016e7>\u001b[0m in \u001b[0;36mmodel_create_train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'poly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \u001b[0mtmp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_name = 'swing'\n",
    "input_axis = ['AX','AY','AZ']\n",
    "mode_list = ['lstm','xgboost','nb','rf','knn','svm']\n",
    "power = 4\n",
    "is_aug = 1\n",
    "\n",
    "for mode_name in mode_list:\n",
    "    prac_machine(dir_name,input_axis,mode_name,power,is_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
