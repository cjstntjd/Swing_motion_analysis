{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/12331 [00:00<01:10, 173.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this model is  X_acc_analysis model \n",
      "\n",
      "\n",
      "load_file_complete\n",
      "make DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:10<00:00, 175.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make DataFrame complete ....\n",
      "label_encoding processing...\n",
      "Done....\n",
      "12331\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.naive_bayes as nb\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import LSTM,Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense \n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout,Input,Dense,Activation,Flatten,SeparableConv2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "\n",
    "target_folder = 'swing'\n",
    "mode = 'X_acc_analysis model'\n",
    "\n",
    "print('this model is ',mode,'\\n\\n')\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk(target_folder):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "print('load_file_complete')\n",
    "print('make DataFrame...')\n",
    "total_data = []\n",
    "total_label = []\n",
    "\n",
    "for z in tqdm(filename_in_dir):\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    total_data.append(tmp_li)\n",
    "    total_label.append(label)\n",
    "    \n",
    "print('make DataFrame complete ....')\n",
    "\n",
    "print('label_encoding processing...')\n",
    "encoder = LabelEncoder()\n",
    "arr_label = encoder.fit_transform(total_label)\n",
    "\n",
    "total_data = np.array(total_data)\n",
    "arr_label = np.array(arr_label)\n",
    "print('Done....')\n",
    "print(len(arr_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 9s 959us/sample - loss: 0.4991 - acc: 0.8114 - val_loss: 0.2175 - val_acc: 0.9291\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 9s 890us/sample - loss: 0.1899 - acc: 0.9387 - val_loss: 0.1434 - val_acc: 0.9570\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 9s 885us/sample - loss: 0.1389 - acc: 0.9572 - val_loss: 0.1353 - val_acc: 0.9542\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 9s 883us/sample - loss: 0.1038 - acc: 0.9698 - val_loss: 0.1096 - val_acc: 0.9668\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 9s 882us/sample - loss: 0.0884 - acc: 0.9724 - val_loss: 0.0768 - val_acc: 0.9777\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 9s 881us/sample - loss: 0.0742 - acc: 0.9768 - val_loss: 0.0644 - val_acc: 0.9789\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 9s 881us/sample - loss: 0.0698 - acc: 0.9764 - val_loss: 0.0660 - val_acc: 0.9777\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 9s 883us/sample - loss: 0.0600 - acc: 0.9803 - val_loss: 0.0646 - val_acc: 0.9781\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 9s 885us/sample - loss: 0.0574 - acc: 0.9811 - val_loss: 0.0552 - val_acc: 0.9793\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 9s 882us/sample - loss: 0.0653 - acc: 0.9792 - val_loss: 0.0705 - val_acc: 0.9769\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 9s 879us/sample - loss: 0.0425 - acc: 0.9845 - val_loss: 0.0642 - val_acc: 0.9809\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 9s 887us/sample - loss: 0.0337 - acc: 0.9896 - val_loss: 0.0680 - val_acc: 0.9830\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 9s 880us/sample - loss: 0.0413 - acc: 0.9867 - val_loss: 0.0678 - val_acc: 0.9761\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 9s 884us/sample - loss: 0.0311 - acc: 0.9905 - val_loss: 0.2003 - val_acc: 0.9473\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 9s 886us/sample - loss: 0.0413 - acc: 0.9858 - val_loss: 0.0593 - val_acc: 0.9809\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 9s 886us/sample - loss: 0.0347 - acc: 0.9868 - val_loss: 0.0819 - val_acc: 0.9753\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 9s 882us/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.0448 - val_acc: 0.9870\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 9s 881us/sample - loss: 0.0220 - acc: 0.9922 - val_loss: 0.0376 - val_acc: 0.9887\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 9s 883us/sample - loss: 0.0163 - acc: 0.9941 - val_loss: 0.0514 - val_acc: 0.9842\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 9s 881us/sample - loss: 0.0167 - acc: 0.9944 - val_loss: 0.0420 - val_acc: 0.9874\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 9s 883us/sample - loss: 0.0197 - acc: 0.9930 - val_loss: 0.0564 - val_acc: 0.9809\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 9s 885us/sample - loss: 0.0235 - acc: 0.9923 - val_loss: 0.0549 - val_acc: 0.9854\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 9s 887us/sample - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0539 - val_acc: 0.9846\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 9s 873us/sample - loss: 0.0136 - acc: 0.9965 - val_loss: 0.0790 - val_acc: 0.9757\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 9s 888us/sample - loss: 0.0219 - acc: 0.9927 - val_loss: 0.0535 - val_acc: 0.9850\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 9s 884us/sample - loss: 0.0148 - acc: 0.9947 - val_loss: 0.0476 - val_acc: 0.9887\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 9s 884us/sample - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0460 - val_acc: 0.9866\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 9s 882us/sample - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0509 - val_acc: 0.9842\n",
      "Best:  [0.8114355, 0.93866587, 0.95721817, 0.96978915, 0.972425, 0.9767843, 0.97637874, 0.9803325, 0.98114353, 0.97921735, 0.984489, 0.989558, 0.98671937, 0.9904704, 0.985807, 0.98682076, 0.99016625, 0.9921938, 0.99412006, 0.99442416, 0.99300486, 0.9922952, 0.9939173, 0.99645174, 0.99270076, 0.9947283, 0.9955393, 0.9967559]\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_smash  -->  fo_drive         err_index number :  73\n",
      "back_smash  -->  back_cut         err_index number :  74\n",
      "back_smash  -->  fo_drive         err_index number :  75\n",
      "back_smash  -->  fo_drive         err_index number :  77\n",
      "back_smash  -->  fo_drive         err_index number :  84\n",
      "back_smash  -->  fo_drive         err_index number :  85\n",
      "back_smash  -->  fo_drive         err_index number :  86\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(180, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128,\n",
    "                     2,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=64,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "total_data = []\n",
    "total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    total_data.append(tmp_li)\n",
    "    total_label.append(label)\n",
    "    \n",
    "total_data = np.array(total_data)\n",
    "nsamples, nx, ny = total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 10s 987us/sample - loss: 0.5140 - acc: 0.8019 - val_loss: 0.4327 - val_acc: 0.8610\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 9s 901us/sample - loss: 0.2282 - acc: 0.9249 - val_loss: 0.1547 - val_acc: 0.9566\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 9s 903us/sample - loss: 0.1501 - acc: 0.9516 - val_loss: 0.1668 - val_acc: 0.9441\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 9s 899us/sample - loss: 0.1202 - acc: 0.9625 - val_loss: 0.1002 - val_acc: 0.9655\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0919 - acc: 0.9708 - val_loss: 0.0987 - val_acc: 0.9680\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 9s 907us/sample - loss: 0.0886 - acc: 0.9713 - val_loss: 0.1179 - val_acc: 0.9688\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0727 - acc: 0.9773 - val_loss: 0.0824 - val_acc: 0.9741\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 9s 903us/sample - loss: 0.0619 - acc: 0.9779 - val_loss: 0.0767 - val_acc: 0.9769\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0528 - acc: 0.9818 - val_loss: 0.0734 - val_acc: 0.9781\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 9s 902us/sample - loss: 0.0651 - acc: 0.9798 - val_loss: 0.1304 - val_acc: 0.9489\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 9s 902us/sample - loss: 0.0639 - acc: 0.9793 - val_loss: 0.0765 - val_acc: 0.9741\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 9s 901us/sample - loss: 0.0522 - acc: 0.9831 - val_loss: 0.0768 - val_acc: 0.9753\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 9s 903us/sample - loss: 0.0350 - acc: 0.9879 - val_loss: 0.0827 - val_acc: 0.9749\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 9s 910us/sample - loss: 0.0353 - acc: 0.9874 - val_loss: 0.0646 - val_acc: 0.9826\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 9s 904us/sample - loss: 0.0328 - acc: 0.9893 - val_loss: 0.0836 - val_acc: 0.9769\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 9s 903us/sample - loss: 0.0361 - acc: 0.9876 - val_loss: 0.0623 - val_acc: 0.9846\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 9s 907us/sample - loss: 0.0273 - acc: 0.9910 - val_loss: 0.1247 - val_acc: 0.9692\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0566 - acc: 0.9813 - val_loss: 0.0703 - val_acc: 0.9826\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0281 - acc: 0.9906 - val_loss: 0.0613 - val_acc: 0.9805\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 9s 898us/sample - loss: 0.0187 - acc: 0.9944 - val_loss: 0.0557 - val_acc: 0.9846\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 9s 901us/sample - loss: 0.0248 - acc: 0.9921 - val_loss: 0.0909 - val_acc: 0.9724\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 9s 905us/sample - loss: 0.0486 - acc: 0.9859 - val_loss: 0.0559 - val_acc: 0.9826\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0493 - val_acc: 0.9842\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 9s 908us/sample - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0600 - val_acc: 0.9850\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 9s 905us/sample - loss: 0.0155 - acc: 0.9956 - val_loss: 0.0580 - val_acc: 0.9822\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 9s 904us/sample - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0591 - val_acc: 0.9838\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 9s 908us/sample - loss: 0.0173 - acc: 0.9935 - val_loss: 0.0519 - val_acc: 0.9850\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 9s 903us/sample - loss: 0.0261 - acc: 0.9918 - val_loss: 0.0544 - val_acc: 0.9862\n",
      "Epoch 29/100\n",
      "9864/9864 [==============================] - 9s 906us/sample - loss: 0.0242 - acc: 0.9925 - val_loss: 0.0734 - val_acc: 0.9805\n",
      "Epoch 30/100\n",
      "9864/9864 [==============================] - 9s 901us/sample - loss: 0.0193 - acc: 0.9944 - val_loss: 0.0550 - val_acc: 0.9858\n",
      "Epoch 31/100\n",
      "9864/9864 [==============================] - 9s 904us/sample - loss: 0.0138 - acc: 0.9950 - val_loss: 0.0496 - val_acc: 0.9866\n",
      "Epoch 32/100\n",
      "9864/9864 [==============================] - 9s 904us/sample - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0939 - val_acc: 0.9749\n",
      "Epoch 33/100\n",
      "9864/9864 [==============================] - 9s 901us/sample - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0528 - val_acc: 0.9854\n",
      "Best:  [0.80190593, 0.92487836, 0.95164233, 0.96248984, 0.9708029, 0.97130984, 0.97729117, 0.97789943, 0.9817518, 0.9798256, 0.97931874, 0.9830698, 0.9879359, 0.987429, 0.9892539, 0.9876318, 0.9909773, 0.9813463, 0.9905718, 0.99442416, 0.99209243, 0.9859083, 0.9919911, 0.99320763, 0.9956407, 0.9953366, 0.99351174, 0.9917883, 0.992498, 0.99442416, 0.9950324, 0.99594486, 0.9923966]\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "fo_drive  -->  fo_smash         err_index number :  12\n",
      "back_smash  -->  back_cut         err_index number :  73\n",
      "back_smash  -->  back_cut         err_index number :  74\n",
      "back_smash  -->  fo_drive         err_index number :  75\n",
      "back_smash  -->  back_cut         err_index number :  77\n",
      "back_smash  -->  back_cut         err_index number :  85\n",
      "back_smash  -->  fo_drive         err_index number :  86\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(180, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128,\n",
    "                     2,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=64,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "total_data = []\n",
    "total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    total_data.append(tmp_li)\n",
    "    total_label.append(label)\n",
    "    \n",
    "total_data = np.array(total_data)\n",
    "nsamples, nx, ny = total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 10s 1ms/sample - loss: 0.5630 - acc: 0.7920 - val_loss: 0.2542 - val_acc: 0.9177\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 9s 940us/sample - loss: 0.2396 - acc: 0.9241 - val_loss: 0.1875 - val_acc: 0.9392\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 9s 943us/sample - loss: 0.1685 - acc: 0.9508 - val_loss: 0.1348 - val_acc: 0.9562\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 9s 944us/sample - loss: 0.1454 - acc: 0.9558 - val_loss: 0.0943 - val_acc: 0.9716\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 9s 945us/sample - loss: 0.1093 - acc: 0.9666 - val_loss: 0.0909 - val_acc: 0.9745\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 9s 947us/sample - loss: 0.1019 - acc: 0.9696 - val_loss: 0.1015 - val_acc: 0.9708\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 9s 945us/sample - loss: 0.1168 - acc: 0.9636 - val_loss: 0.0960 - val_acc: 0.9724\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 9s 941us/sample - loss: 0.0890 - acc: 0.9725 - val_loss: 0.1060 - val_acc: 0.9708\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 9s 947us/sample - loss: 0.0759 - acc: 0.9772 - val_loss: 0.0598 - val_acc: 0.9826\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 9s 941us/sample - loss: 0.0672 - acc: 0.9797 - val_loss: 0.0729 - val_acc: 0.9801\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 9s 941us/sample - loss: 0.0657 - acc: 0.9808 - val_loss: 0.1207 - val_acc: 0.9680\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 9s 949us/sample - loss: 0.0510 - acc: 0.9855 - val_loss: 0.0631 - val_acc: 0.9854\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 9s 943us/sample - loss: 0.0509 - acc: 0.9840 - val_loss: 0.0673 - val_acc: 0.9834\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 9s 946us/sample - loss: 0.0604 - acc: 0.9809 - val_loss: 0.0693 - val_acc: 0.9801\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 9s 946us/sample - loss: 0.0701 - acc: 0.9773 - val_loss: 0.0770 - val_acc: 0.9773\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 9s 948us/sample - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0674 - val_acc: 0.9818\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 9s 949us/sample - loss: 0.0422 - acc: 0.9862 - val_loss: 0.0769 - val_acc: 0.9765\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 9s 950us/sample - loss: 0.0469 - acc: 0.9847 - val_loss: 0.0540 - val_acc: 0.9846\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 9s 941us/sample - loss: 0.0359 - acc: 0.9888 - val_loss: 0.0703 - val_acc: 0.9801\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 9s 946us/sample - loss: 0.0372 - acc: 0.9897 - val_loss: 0.0706 - val_acc: 0.9805\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 9s 948us/sample - loss: 0.0344 - acc: 0.9888 - val_loss: 0.0651 - val_acc: 0.9830\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 9s 943us/sample - loss: 0.0326 - acc: 0.9895 - val_loss: 0.0515 - val_acc: 0.9846\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 9s 946us/sample - loss: 0.0456 - acc: 0.9855 - val_loss: 0.0814 - val_acc: 0.9781\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 9s 944us/sample - loss: 0.0366 - acc: 0.9877 - val_loss: 0.0621 - val_acc: 0.9805\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 9s 943us/sample - loss: 0.0378 - acc: 0.9876 - val_loss: 0.0473 - val_acc: 0.9874\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 9s 943us/sample - loss: 0.0300 - acc: 0.9910 - val_loss: 0.0634 - val_acc: 0.9846\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 9s 949us/sample - loss: 0.0349 - acc: 0.9897 - val_loss: 0.0666 - val_acc: 0.9842\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 9s 940us/sample - loss: 0.0329 - acc: 0.9901 - val_loss: 0.0572 - val_acc: 0.9870\n",
      "Epoch 29/100\n",
      "9864/9864 [==============================] - 9s 941us/sample - loss: 0.0212 - acc: 0.9927 - val_loss: 0.0772 - val_acc: 0.9822\n",
      "Epoch 30/100\n",
      "9864/9864 [==============================] - 9s 941us/sample - loss: 0.0319 - acc: 0.9903 - val_loss: 0.0535 - val_acc: 0.9862\n",
      "Epoch 31/100\n",
      "9864/9864 [==============================] - 9s 945us/sample - loss: 0.0306 - acc: 0.9897 - val_loss: 0.0611 - val_acc: 0.9838\n",
      "Epoch 32/100\n",
      "9864/9864 [==============================] - 9s 944us/sample - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0666 - val_acc: 0.9858\n",
      "Epoch 33/100\n",
      "9864/9864 [==============================] - 9s 947us/sample - loss: 0.0277 - acc: 0.9921 - val_loss: 0.0397 - val_acc: 0.9874\n",
      "Epoch 34/100\n",
      "9864/9864 [==============================] - 9s 952us/sample - loss: 0.0301 - acc: 0.9909 - val_loss: 0.0488 - val_acc: 0.9882\n",
      "Epoch 35/100\n",
      "9864/9864 [==============================] - 9s 940us/sample - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0525 - val_acc: 0.9887\n",
      "Epoch 36/100\n",
      "9864/9864 [==============================] - 9s 943us/sample - loss: 0.0214 - acc: 0.9930 - val_loss: 0.0589 - val_acc: 0.9870\n",
      "Epoch 37/100\n",
      "9864/9864 [==============================] - 9s 944us/sample - loss: 0.0182 - acc: 0.9937 - val_loss: 0.0643 - val_acc: 0.9858\n",
      "Epoch 38/100\n",
      "9864/9864 [==============================] - 9s 947us/sample - loss: 0.0293 - acc: 0.9916 - val_loss: 0.0849 - val_acc: 0.9793\n",
      "Epoch 39/100\n",
      "9864/9864 [==============================] - 9s 945us/sample - loss: 0.0566 - acc: 0.9850 - val_loss: 0.0646 - val_acc: 0.9854\n",
      "Epoch 40/100\n",
      "9864/9864 [==============================] - 9s 942us/sample - loss: 0.0303 - acc: 0.9909 - val_loss: 0.0609 - val_acc: 0.9838\n",
      "Epoch 41/100\n",
      "9864/9864 [==============================] - 9s 948us/sample - loss: 0.0312 - acc: 0.9914 - val_loss: 0.0692 - val_acc: 0.9834\n",
      "Epoch 42/100\n",
      "9864/9864 [==============================] - 9s 946us/sample - loss: 0.0270 - acc: 0.9917 - val_loss: 0.0698 - val_acc: 0.9834\n",
      "Epoch 43/100\n",
      "9864/9864 [==============================] - 9s 950us/sample - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0607 - val_acc: 0.9854\n",
      "Best:  [0.7919708, 0.9240673, 0.9508313, 0.95579886, 0.9666464, 0.9695864, 0.96360505, 0.9725264, 0.9771898, 0.9797242, 0.98083943, 0.98550284, 0.98398215, 0.9809408, 0.97729117, 0.9818532, 0.9862125, 0.9846918, 0.9888483, 0.98965937, 0.9888483, 0.9894566, 0.98550284, 0.9877332, 0.9876318, 0.9909773, 0.98965937, 0.99006486, 0.99270076, 0.99026763, 0.98965937, 0.9918897, 0.99209243, 0.9908759, 0.9923966, 0.99300486, 0.9937145, 0.99158555, 0.98499596, 0.9908759, 0.9913828, 0.99168694, 0.9929035]\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_smash  -->  fo_drive         err_index number :  73\n",
      "back_smash  -->  back_cut         err_index number :  74\n",
      "back_smash  -->  back_drive         err_index number :  75\n",
      "back_smash  -->  back_drive         err_index number :  77\n",
      "back_smash  -->  back_cut         err_index number :  84\n",
      "back_smash  -->  back_drive         err_index number :  85\n",
      "back_smash  -->  back_drive         err_index number :  86\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(180, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(512,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=64,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "s_total_data = []\n",
    "s_total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    s_total_data.append(tmp_li)\n",
    "    s_total_label.append(label)\n",
    "    \n",
    "s_total_data = np.array(s_total_data)\n",
    "nsamples, nx, ny = s_total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(s_total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == s_total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(s_total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 4s 375us/sample - loss: 1.3496 - acc: 0.4593 - val_loss: 0.7440 - val_acc: 0.7454\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.6741 - acc: 0.7617 - val_loss: 0.3938 - val_acc: 0.8687\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.4636 - acc: 0.8473 - val_loss: 0.3052 - val_acc: 0.9051\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.3686 - acc: 0.8875 - val_loss: 0.2556 - val_acc: 0.9185\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.3181 - acc: 0.9089 - val_loss: 0.2322 - val_acc: 0.9274\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.2853 - acc: 0.9203 - val_loss: 0.2320 - val_acc: 0.9287\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.2655 - acc: 0.9258 - val_loss: 0.1944 - val_acc: 0.9404\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.2456 - acc: 0.9315 - val_loss: 0.1759 - val_acc: 0.9493\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.2212 - acc: 0.9376 - val_loss: 0.1845 - val_acc: 0.9457\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.2015 - acc: 0.9444 - val_loss: 0.1530 - val_acc: 0.9538\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.1866 - acc: 0.9470 - val_loss: 0.1313 - val_acc: 0.9595\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1842 - acc: 0.9483 - val_loss: 0.1376 - val_acc: 0.9570\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.1789 - acc: 0.9503 - val_loss: 0.1293 - val_acc: 0.9615\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1581 - acc: 0.9586 - val_loss: 0.1315 - val_acc: 0.9611\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.1499 - acc: 0.9610 - val_loss: 0.1213 - val_acc: 0.9623\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1391 - acc: 0.9622 - val_loss: 0.1220 - val_acc: 0.9647\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.1444 - acc: 0.9617 - val_loss: 0.1064 - val_acc: 0.9660\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.1386 - acc: 0.9641 - val_loss: 0.1146 - val_acc: 0.9647\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.1306 - acc: 0.9674 - val_loss: 0.1292 - val_acc: 0.9611\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.1261 - acc: 0.9680 - val_loss: 0.1552 - val_acc: 0.9570\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.1381 - acc: 0.9630 - val_loss: 0.0971 - val_acc: 0.9712\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1117 - acc: 0.9713 - val_loss: 0.0951 - val_acc: 0.9696\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.1076 - acc: 0.9709 - val_loss: 0.1080 - val_acc: 0.9684\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.1061 - acc: 0.9729 - val_loss: 0.0872 - val_acc: 0.9757\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.1064 - acc: 0.9725 - val_loss: 0.1066 - val_acc: 0.9680\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.1002 - acc: 0.9726 - val_loss: 0.0879 - val_acc: 0.9749\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1029 - acc: 0.9726 - val_loss: 0.0928 - val_acc: 0.9724\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0969 - acc: 0.9734 - val_loss: 0.0966 - val_acc: 0.9696\n",
      "Epoch 29/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0889 - acc: 0.9766 - val_loss: 0.0825 - val_acc: 0.9749\n",
      "Epoch 30/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0916 - acc: 0.9758 - val_loss: 0.0909 - val_acc: 0.9737\n",
      "Epoch 31/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0927 - acc: 0.9750 - val_loss: 0.0921 - val_acc: 0.9712\n",
      "Epoch 32/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0939 - acc: 0.9758 - val_loss: 0.0945 - val_acc: 0.9708\n",
      "Epoch 33/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0894 - acc: 0.9767 - val_loss: 0.0917 - val_acc: 0.9708\n",
      "Epoch 34/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0933 - acc: 0.9742 - val_loss: 0.0799 - val_acc: 0.9749\n",
      "Epoch 35/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0972 - acc: 0.9748 - val_loss: 0.0875 - val_acc: 0.9728\n",
      "Epoch 36/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0872 - acc: 0.9761 - val_loss: 0.0759 - val_acc: 0.9781\n",
      "Epoch 37/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0826 - acc: 0.9774 - val_loss: 0.0800 - val_acc: 0.9724\n",
      "Epoch 38/100\n",
      "9864/9864 [==============================] - 2s 205us/sample - loss: 0.0804 - acc: 0.9784 - val_loss: 0.0843 - val_acc: 0.9761\n",
      "Epoch 39/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0829 - acc: 0.9783 - val_loss: 0.0863 - val_acc: 0.9753\n",
      "Epoch 40/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0864 - acc: 0.9770 - val_loss: 0.0692 - val_acc: 0.9805\n",
      "Epoch 41/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0760 - acc: 0.9783 - val_loss: 0.0765 - val_acc: 0.9765\n",
      "Epoch 42/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0711 - acc: 0.9800 - val_loss: 0.0808 - val_acc: 0.9761\n",
      "Epoch 43/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0708 - acc: 0.9799 - val_loss: 0.0800 - val_acc: 0.9777\n",
      "Epoch 44/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0605 - acc: 0.9828 - val_loss: 0.0702 - val_acc: 0.9773\n",
      "Epoch 45/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0671 - acc: 0.9806 - val_loss: 0.0659 - val_acc: 0.9801\n",
      "Epoch 46/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0646 - acc: 0.9834 - val_loss: 0.0800 - val_acc: 0.9745\n",
      "Epoch 47/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0622 - acc: 0.9846 - val_loss: 0.0680 - val_acc: 0.9818\n",
      "Epoch 48/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0681 - acc: 0.9801 - val_loss: 0.0617 - val_acc: 0.9809\n",
      "Epoch 49/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0650 - acc: 0.9821 - val_loss: 0.0725 - val_acc: 0.9793\n",
      "Epoch 50/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0807 - acc: 0.9770 - val_loss: 0.0778 - val_acc: 0.9745\n",
      "Epoch 51/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0696 - acc: 0.9818 - val_loss: 0.0642 - val_acc: 0.9797\n",
      "Epoch 52/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.0824 - acc: 0.9769 - val_loss: 0.0704 - val_acc: 0.9781\n",
      "Epoch 53/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0633 - acc: 0.9836 - val_loss: 0.0691 - val_acc: 0.9789\n",
      "Epoch 54/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0580 - acc: 0.9840 - val_loss: 0.0681 - val_acc: 0.9781\n",
      "Epoch 55/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0602 - acc: 0.9841 - val_loss: 0.0652 - val_acc: 0.9781\n",
      "Epoch 56/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0578 - acc: 0.9834 - val_loss: 0.0647 - val_acc: 0.9777\n",
      "Epoch 57/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0592 - acc: 0.9829 - val_loss: 0.0725 - val_acc: 0.9765\n",
      "Epoch 58/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0534 - acc: 0.9856 - val_loss: 0.0662 - val_acc: 0.9797\n",
      "Best:  [0.45934713, 0.76165855, 0.8473236, 0.8874696, 0.9088605, 0.9203163, 0.9257907, 0.93146795, 0.93755066, 0.9444444, 0.9469789, 0.94829684, 0.9503244, 0.9586375, 0.9609692, 0.96218574, 0.9616788, 0.9641119, 0.967356, 0.9679643, 0.9629968, 0.97130984, 0.9709043, 0.97293186, 0.9725264, 0.97262776, 0.97262776, 0.97343874, 0.9765815, 0.9757705, 0.97495943, 0.9757705, 0.9766829, 0.9742498, 0.9747567, 0.97607464, 0.97739255, 0.9784063, 0.9783049, 0.976987, 0.9783049, 0.9800284, 0.979927, 0.9827656, 0.98063666, 0.9833739, 0.9845904, 0.9801298, 0.98205596, 0.976987, 0.9817518, 0.9768856, 0.98357666, 0.98398215, 0.98408353, 0.9833739, 0.982867, 0.9856042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_smash  -->  back_cut         err_index number :  73\n",
      "back_smash  -->  back_cut         err_index number :  74\n",
      "back_smash  -->  back_cut         err_index number :  75\n",
      "back_smash  -->  back_cut         err_index number :  77\n",
      "back_smash  -->  back_cut         err_index number :  84\n",
      "back_smash  -->  back_cut         err_index number :  85\n",
      "back_smash  -->  back_cut         err_index number :  86\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(60, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Conv1D(512,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=3))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(LSTM(128,dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=256,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "s_total_data = []\n",
    "s_total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    s_total_data.append(tmp_li)\n",
    "    s_total_label.append(label)\n",
    "    \n",
    "s_total_data = np.array(s_total_data)\n",
    "nsamples, nx, ny = s_total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(s_total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == s_total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(s_total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 4s 412us/sample - loss: 1.1463 - acc: 0.5444 - val_loss: 0.5276 - val_acc: 0.8358\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.4086 - acc: 0.8624 - val_loss: 0.2779 - val_acc: 0.9173\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.2781 - acc: 0.9107 - val_loss: 0.2012 - val_acc: 0.9469\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.2374 - acc: 0.9263 - val_loss: 0.1870 - val_acc: 0.9408\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1892 - acc: 0.9404 - val_loss: 0.1668 - val_acc: 0.9501\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1753 - acc: 0.9470 - val_loss: 0.1522 - val_acc: 0.9566\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.1557 - acc: 0.9512 - val_loss: 0.1524 - val_acc: 0.9518\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.1281 - acc: 0.9612 - val_loss: 0.1266 - val_acc: 0.9660\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.1160 - acc: 0.9642 - val_loss: 0.1116 - val_acc: 0.9688\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.1098 - acc: 0.9653 - val_loss: 0.1045 - val_acc: 0.9684\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0974 - acc: 0.9706 - val_loss: 0.0947 - val_acc: 0.9712\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0914 - acc: 0.9709 - val_loss: 0.1013 - val_acc: 0.9684\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.0871 - acc: 0.9727 - val_loss: 0.0918 - val_acc: 0.9724\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0801 - acc: 0.9742 - val_loss: 0.1074 - val_acc: 0.9696\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0855 - acc: 0.9713 - val_loss: 0.0833 - val_acc: 0.9765\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.0745 - acc: 0.9744 - val_loss: 0.0839 - val_acc: 0.9737\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0742 - acc: 0.9760 - val_loss: 0.1191 - val_acc: 0.9627\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0727 - acc: 0.9769 - val_loss: 0.0817 - val_acc: 0.9720\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0595 - acc: 0.9799 - val_loss: 0.0698 - val_acc: 0.9793\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0615 - acc: 0.9793 - val_loss: 0.0818 - val_acc: 0.9745\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0574 - acc: 0.9808 - val_loss: 0.0746 - val_acc: 0.9781\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0538 - acc: 0.9826 - val_loss: 0.0733 - val_acc: 0.9773\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0567 - acc: 0.9803 - val_loss: 0.0694 - val_acc: 0.9789\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0528 - acc: 0.9815 - val_loss: 0.0702 - val_acc: 0.9801\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 2s 205us/sample - loss: 0.0455 - acc: 0.9844 - val_loss: 0.0751 - val_acc: 0.9769\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0438 - acc: 0.9840 - val_loss: 0.0686 - val_acc: 0.9797\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0408 - acc: 0.9860 - val_loss: 0.0624 - val_acc: 0.9805\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0383 - acc: 0.9868 - val_loss: 0.0704 - val_acc: 0.9785\n",
      "Epoch 29/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0408 - acc: 0.9864 - val_loss: 0.0711 - val_acc: 0.9793\n",
      "Epoch 30/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0398 - acc: 0.9856 - val_loss: 0.0796 - val_acc: 0.9757\n",
      "Epoch 31/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0411 - acc: 0.9853 - val_loss: 0.0760 - val_acc: 0.9753\n",
      "Epoch 32/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0426 - acc: 0.9842 - val_loss: 0.0614 - val_acc: 0.9838\n",
      "Epoch 33/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0387 - acc: 0.9868 - val_loss: 0.0663 - val_acc: 0.9826\n",
      "Epoch 34/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0318 - acc: 0.9882 - val_loss: 0.0696 - val_acc: 0.9814\n",
      "Epoch 35/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0351 - acc: 0.9873 - val_loss: 0.0809 - val_acc: 0.9753\n",
      "Epoch 36/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.0356 - acc: 0.9883 - val_loss: 0.0734 - val_acc: 0.9785\n",
      "Epoch 37/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.0259 - acc: 0.9907 - val_loss: 0.0665 - val_acc: 0.9809\n",
      "Epoch 38/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0336 - acc: 0.9887 - val_loss: 0.0681 - val_acc: 0.9789\n",
      "Epoch 39/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0313 - acc: 0.9886 - val_loss: 0.0984 - val_acc: 0.9716\n",
      "Epoch 40/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.0330 - acc: 0.9895 - val_loss: 0.0648 - val_acc: 0.9826\n",
      "Epoch 41/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.0245 - acc: 0.9914 - val_loss: 0.0677 - val_acc: 0.9797\n",
      "Epoch 42/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0856 - val_acc: 0.9785\n",
      "Best:  [0.5444039, 0.862429, 0.9106853, 0.92629766, 0.9403893, 0.9469789, 0.95123684, 0.9611719, 0.9642133, 0.96532845, 0.9706002, 0.9709043, 0.9727291, 0.9742498, 0.97130984, 0.97435117, 0.97597325, 0.9768856, 0.979927, 0.97931874, 0.98083943, 0.98256284, 0.9803325, 0.9815491, 0.9843877, 0.98398215, 0.9860097, 0.98682076, 0.98641527, 0.9856042, 0.98530006, 0.9841849, 0.98682076, 0.98824006, 0.98732764, 0.98834145, 0.9906732, 0.98874694, 0.98864555, 0.9894566, 0.9913828, 0.993309]\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_smash  -->  fo_drive         err_index number :  73\n",
      "back_smash  -->  fo_drive         err_index number :  74\n",
      "back_smash  -->  fo_drive         err_index number :  75\n",
      "back_smash  -->  fo_drive         err_index number :  77\n",
      "back_smash  -->  fo_drive         err_index number :  84\n",
      "back_smash  -->  fo_drive         err_index number :  85\n",
      "back_smash  -->  fo_drive         err_index number :  86\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(60, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv1D(256,\n",
    "                     1,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=3))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(LSTM(256,dropout=0.2, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=256,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "s_total_data = []\n",
    "s_total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    s_total_data.append(tmp_li)\n",
    "    s_total_label.append(label)\n",
    "    \n",
    "s_total_data = np.array(s_total_data)\n",
    "nsamples, nx, ny = s_total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(s_total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == s_total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(s_total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 4s 444us/sample - loss: 1.0869 - acc: 0.5747 - val_loss: 0.4904 - val_acc: 0.8439\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.4183 - acc: 0.8499 - val_loss: 0.2953 - val_acc: 0.8987\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.3022 - acc: 0.9016 - val_loss: 0.2239 - val_acc: 0.9331\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.2316 - acc: 0.9272 - val_loss: 0.1991 - val_acc: 0.9380\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.1965 - acc: 0.9395 - val_loss: 0.1635 - val_acc: 0.9501\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.1758 - acc: 0.9469 - val_loss: 0.1454 - val_acc: 0.9534\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.1617 - acc: 0.9492 - val_loss: 0.1530 - val_acc: 0.9489\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.1473 - acc: 0.9538 - val_loss: 0.1375 - val_acc: 0.9582\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.1225 - acc: 0.9636 - val_loss: 0.1141 - val_acc: 0.9655\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.1110 - acc: 0.9636 - val_loss: 0.1050 - val_acc: 0.9688\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.1000 - acc: 0.9687 - val_loss: 0.1008 - val_acc: 0.9720\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0994 - acc: 0.9678 - val_loss: 0.0979 - val_acc: 0.9688\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0829 - acc: 0.9746 - val_loss: 0.0892 - val_acc: 0.9712\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 2s 214us/sample - loss: 0.0780 - acc: 0.9758 - val_loss: 0.0789 - val_acc: 0.9757\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0768 - acc: 0.9766 - val_loss: 0.0826 - val_acc: 0.9769\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0684 - acc: 0.9778 - val_loss: 0.0827 - val_acc: 0.9765\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0708 - acc: 0.9760 - val_loss: 0.0743 - val_acc: 0.9761\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0672 - acc: 0.9789 - val_loss: 0.0804 - val_acc: 0.9745\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0620 - acc: 0.9798 - val_loss: 0.0713 - val_acc: 0.9781\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0586 - acc: 0.9810 - val_loss: 0.0686 - val_acc: 0.9773\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0542 - acc: 0.9812 - val_loss: 0.0681 - val_acc: 0.9805\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0505 - acc: 0.9822 - val_loss: 0.0691 - val_acc: 0.9801\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0747 - acc: 0.9749 - val_loss: 0.0722 - val_acc: 0.9773\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0525 - acc: 0.9838 - val_loss: 0.0708 - val_acc: 0.9769\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0469 - acc: 0.9838 - val_loss: 0.0791 - val_acc: 0.9741\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 2s 214us/sample - loss: 0.0465 - acc: 0.9851 - val_loss: 0.0697 - val_acc: 0.9805\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 2s 214us/sample - loss: 0.0429 - acc: 0.9857 - val_loss: 0.0650 - val_acc: 0.9822\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0730 - val_acc: 0.9777\n",
      "Epoch 29/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0468 - acc: 0.9843 - val_loss: 0.0666 - val_acc: 0.9793\n",
      "Epoch 30/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0469 - acc: 0.9844 - val_loss: 0.0705 - val_acc: 0.9793\n",
      "Epoch 31/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0384 - acc: 0.9871 - val_loss: 0.0679 - val_acc: 0.9801\n",
      "Epoch 32/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0335 - acc: 0.9888 - val_loss: 0.0730 - val_acc: 0.9785\n",
      "Epoch 33/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0360 - acc: 0.9877 - val_loss: 0.0624 - val_acc: 0.9818\n",
      "Epoch 34/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0323 - acc: 0.9893 - val_loss: 0.0670 - val_acc: 0.9805\n",
      "Epoch 35/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0451 - acc: 0.9853 - val_loss: 0.0630 - val_acc: 0.9801\n",
      "Epoch 36/100\n",
      "9864/9864 [==============================] - 2s 214us/sample - loss: 0.0284 - acc: 0.9908 - val_loss: 0.0665 - val_acc: 0.9826\n",
      "Epoch 37/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0317 - acc: 0.9894 - val_loss: 0.0773 - val_acc: 0.9789\n",
      "Epoch 38/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0304 - acc: 0.9887 - val_loss: 0.0750 - val_acc: 0.9789\n",
      "Epoch 39/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0317 - acc: 0.9899 - val_loss: 0.0779 - val_acc: 0.9793\n",
      "Epoch 40/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0383 - acc: 0.9870 - val_loss: 0.0716 - val_acc: 0.9789\n",
      "Epoch 41/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0361 - acc: 0.9886 - val_loss: 0.0714 - val_acc: 0.9822\n",
      "Epoch 42/100\n",
      "9864/9864 [==============================] - 2s 210us/sample - loss: 0.0368 - acc: 0.9878 - val_loss: 0.0674 - val_acc: 0.9814\n",
      "Epoch 43/100\n",
      "9864/9864 [==============================] - 2s 214us/sample - loss: 0.0313 - acc: 0.9894 - val_loss: 0.0593 - val_acc: 0.9830\n",
      "Epoch 44/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0294 - acc: 0.9902 - val_loss: 0.0667 - val_acc: 0.9830\n",
      "Epoch 45/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0289 - acc: 0.9901 - val_loss: 0.0643 - val_acc: 0.9830\n",
      "Epoch 46/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0352 - acc: 0.9888 - val_loss: 0.0691 - val_acc: 0.9818\n",
      "Epoch 47/100\n",
      "9864/9864 [==============================] - 2s 212us/sample - loss: 0.0265 - acc: 0.9907 - val_loss: 0.0749 - val_acc: 0.9801\n",
      "Epoch 48/100\n",
      "9864/9864 [==============================] - 2s 209us/sample - loss: 0.0257 - acc: 0.9921 - val_loss: 0.0652 - val_acc: 0.9838\n",
      "Epoch 49/100\n",
      "9864/9864 [==============================] - 2s 211us/sample - loss: 0.0193 - acc: 0.9935 - val_loss: 0.0657 - val_acc: 0.9850\n",
      "Epoch 50/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0192 - acc: 0.9929 - val_loss: 0.0662 - val_acc: 0.9838\n",
      "Epoch 51/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0177 - acc: 0.9940 - val_loss: 0.0861 - val_acc: 0.9741\n",
      "Epoch 52/100\n",
      "9864/9864 [==============================] - 2s 213us/sample - loss: 0.0240 - acc: 0.9914 - val_loss: 0.0703 - val_acc: 0.9834\n",
      "Epoch 53/100\n",
      "9864/9864 [==============================] - 2s 208us/sample - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0733 - val_acc: 0.9777\n",
      "Best:  [0.57471615, 0.84985805, 0.90156126, 0.92721003, 0.9394769, 0.94687754, 0.9492093, 0.9537713, 0.96360505, 0.96360505, 0.96867394, 0.9677616, 0.97455394, 0.9757705, 0.9765815, 0.97779804, 0.97597325, 0.97891325, 0.9798256, 0.98104215, 0.9812449, 0.98215735, 0.97485805, 0.9837794, 0.9837794, 0.98509735, 0.9857056, 0.98722625, 0.9842863, 0.9843877, 0.9871249, 0.9888483, 0.9877332, 0.9892539, 0.98530006, 0.9907745, 0.9893552, 0.98874694, 0.98986214, 0.98702353, 0.98864555, 0.9878346, 0.9893552, 0.99016625, 0.99006486, 0.9888483, 0.9906732, 0.99209243, 0.99351174, 0.9929035, 0.9940187, 0.9913828, 0.9907745]\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "back_smash  -->  fo_drive         err_index number :  73\n",
      "back_smash  -->  fo_drive         err_index number :  74\n",
      "back_smash  -->  back_drive         err_index number :  75\n",
      "back_smash  -->  back_drive         err_index number :  77\n",
      "back_smash  -->  fo_drive         err_index number :  84\n",
      "back_smash  -->  fo_drive         err_index number :  85\n",
      "back_smash  -->  back_drive         err_index number :  86\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(60, input_shape=(60,3),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv1D(256,\n",
    "                     1,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=3))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(LSTM(256,dropout=0.2, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=256,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "s_total_data = []\n",
    "s_total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(df['AX'][i]/1000)\n",
    "        tmp.append(df['AY'][i]/1000)\n",
    "        tmp.append(df['AZ'][i]/1000)\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    s_total_data.append(tmp_li)\n",
    "    s_total_label.append(label)\n",
    "    \n",
    "s_total_data = np.array(s_total_data)\n",
    "nsamples, nx, ny = s_total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(s_total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == s_total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(s_total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/12331 [00:00<01:11, 172.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this model is  X_acc_analysis model \n",
      "\n",
      "\n",
      "load_file_complete\n",
      "make DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:11<00:00, 172.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make DataFrame complete ....\n",
      "label_encoding processing...\n",
      "Done....\n",
      "12331\n",
      "fitting  X_acc_analysis model  is complete...\n",
      "X_acc_analysis model score is : 0.8706931495743818\n",
      "Validation Result...\n",
      "hit:  2148  miss :  319\n",
      "\n",
      "\n",
      "now test new data..\n",
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "fo_drive  -->  fo_smash err_index :  11\n",
      "back_short  -->  back_smash err_index :  65\n",
      "back_smash  -->  fo_cut err_index :  84\n",
      "hit:  84  miss :  3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.naive_bayes as nb\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import LSTM,Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense \n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout,Input,Dense,Activation,Flatten,SeparableConv2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "\n",
    "target_folder = 'swing'\n",
    "mode = 'X_acc_analysis model'\n",
    "\n",
    "print('this model is ',mode,'\\n\\n')\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk(target_folder):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "print('load_file_complete')\n",
    "print('make DataFrame...')\n",
    "total_data = []\n",
    "total_label = []\n",
    "\n",
    "for z in tqdm(filename_in_dir):\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(((df['AX'][i]/1000)**2 + (df['AY'][i]/1000)**2 + (df['AZ'][i]/1000)**2)**0.5 )\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    total_data.append(tmp_li)\n",
    "    total_label.append(label)\n",
    "    \n",
    "print('make DataFrame complete ....')\n",
    "\n",
    "print('label_encoding processing...')\n",
    "encoder = LabelEncoder()\n",
    "arr_label = encoder.fit_transform(total_label)\n",
    "\n",
    "total_data = np.array(total_data)\n",
    "arr_label = np.array(arr_label)\n",
    "print('Done....')\n",
    "print(len(arr_label))\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "#####here to change####\n",
    "######################################################################\n",
    "\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [10,15,20,30,40,50,100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [3,4,5,6,7,8,9,10,11,12],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "mod = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10,n_jobs=-1)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "\n",
    "predict_model = mod.fit(d2_train_dataset,y_train)\n",
    "print('fitting ',mode,' is complete...')\n",
    "print(mode,'score is :',predict_model.score(d2_test_dataset,y_test))\n",
    "\n",
    "prediction = predict_model.predict(d2_test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "for x in range(len(y_test)):\n",
    "    if prediction[x] == y_test[x]:\n",
    "        hit+=1\n",
    "    else:\n",
    "        miss+=1\n",
    "\n",
    "print('Validation Result...')\n",
    "print('hit: ',hit,' miss : ',miss)\n",
    "\n",
    "print('\\n\\nnow test new data..')\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "total_data = []\n",
    "total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(((df['AX'][i]/1000)**2 + (df['AY'][i]/1000)**2 + (df['AZ'][i]/1000)**2)**0.5 )\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    total_data.append(tmp_li)\n",
    "    total_label.append(label)\n",
    "    \n",
    "total_data = np.array(total_data)\n",
    "nsamples, nx, ny = total_data.shape\n",
    "sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = predict_model.predict(sample)\n",
    "\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(total_label[x],' --> ' ,lab[x],'err_index : ',x)\n",
    "\n",
    "print('hit: ',hit,' miss : ',miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1277.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AX'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/12331 [00:00<01:09, 176.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this model is  X_acc_analysis model \n",
      "\n",
      "\n",
      "load_file_complete\n",
      "make DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12331/12331 [01:10<00:00, 175.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make DataFrame complete ....\n",
      "label_encoding processing...\n",
      "Done....\n",
      "12331\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 9864 samples, validate on 2467 samples\n",
      "Epoch 1/100\n",
      "9864/9864 [==============================] - 5s 466us/sample - loss: 1.8279 - acc: 0.2233 - val_loss: 1.7050 - val_acc: 0.2769\n",
      "Epoch 2/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 1.5589 - acc: 0.3639 - val_loss: 1.5206 - val_acc: 0.3912\n",
      "Epoch 3/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 1.3671 - acc: 0.4532 - val_loss: 1.1243 - val_acc: 0.5805\n",
      "Epoch 4/100\n",
      "9864/9864 [==============================] - 2s 202us/sample - loss: 1.0352 - acc: 0.5975 - val_loss: 0.8792 - val_acc: 0.6737\n",
      "Epoch 5/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.8769 - acc: 0.6523 - val_loss: 0.7794 - val_acc: 0.6769\n",
      "Epoch 6/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.7749 - acc: 0.6944 - val_loss: 0.7047 - val_acc: 0.7300\n",
      "Epoch 7/100\n",
      "9864/9864 [==============================] - 2s 205us/sample - loss: 0.7026 - acc: 0.7240 - val_loss: 0.6092 - val_acc: 0.7552\n",
      "Epoch 8/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.6680 - acc: 0.7401 - val_loss: 0.5774 - val_acc: 0.7730\n",
      "Epoch 9/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.6306 - acc: 0.7562 - val_loss: 0.5671 - val_acc: 0.7844\n",
      "Epoch 10/100\n",
      "9864/9864 [==============================] - 2s 202us/sample - loss: 0.5909 - acc: 0.7720 - val_loss: 0.5345 - val_acc: 0.7957\n",
      "Epoch 11/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.5556 - acc: 0.7887 - val_loss: 0.5135 - val_acc: 0.7998\n",
      "Epoch 12/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.5466 - acc: 0.7865 - val_loss: 0.5223 - val_acc: 0.7933\n",
      "Epoch 13/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.5346 - acc: 0.7907 - val_loss: 0.4809 - val_acc: 0.8212\n",
      "Epoch 14/100\n",
      "9864/9864 [==============================] - 2s 202us/sample - loss: 0.5083 - acc: 0.8008 - val_loss: 0.4858 - val_acc: 0.8196\n",
      "Epoch 15/100\n",
      "9864/9864 [==============================] - 2s 199us/sample - loss: 0.4951 - acc: 0.8104 - val_loss: 0.4532 - val_acc: 0.8391\n",
      "Epoch 16/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.4679 - acc: 0.8193 - val_loss: 0.4411 - val_acc: 0.8423\n",
      "Epoch 17/100\n",
      "9864/9864 [==============================] - 2s 205us/sample - loss: 0.4592 - acc: 0.8251 - val_loss: 0.4058 - val_acc: 0.8500\n",
      "Epoch 18/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.4396 - acc: 0.8375 - val_loss: 0.4657 - val_acc: 0.8334\n",
      "Epoch 19/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.4411 - acc: 0.8298 - val_loss: 0.4071 - val_acc: 0.8585\n",
      "Epoch 20/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.4257 - acc: 0.8420 - val_loss: 0.4018 - val_acc: 0.8553\n",
      "Epoch 21/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.4175 - acc: 0.8374 - val_loss: 0.3968 - val_acc: 0.8577\n",
      "Epoch 22/100\n",
      "9864/9864 [==============================] - 2s 202us/sample - loss: 0.4041 - acc: 0.8441 - val_loss: 0.4121 - val_acc: 0.8464\n",
      "Epoch 23/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.3840 - acc: 0.8531 - val_loss: 0.3927 - val_acc: 0.8630\n",
      "Epoch 24/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.3942 - acc: 0.8495 - val_loss: 0.3727 - val_acc: 0.8610\n",
      "Epoch 25/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.3810 - acc: 0.8562 - val_loss: 0.3827 - val_acc: 0.8589\n",
      "Epoch 26/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.3627 - acc: 0.8626 - val_loss: 0.3718 - val_acc: 0.8602\n",
      "Epoch 27/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.3616 - acc: 0.8585 - val_loss: 0.3825 - val_acc: 0.8529\n",
      "Epoch 28/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.3500 - acc: 0.8639 - val_loss: 0.3653 - val_acc: 0.8610\n",
      "Epoch 29/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.3318 - acc: 0.8757 - val_loss: 0.3536 - val_acc: 0.8723\n",
      "Epoch 30/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.3308 - acc: 0.8767 - val_loss: 0.3627 - val_acc: 0.8699\n",
      "Epoch 31/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.3236 - acc: 0.8778 - val_loss: 0.3566 - val_acc: 0.8727\n",
      "Epoch 32/100\n",
      "9864/9864 [==============================] - 2s 205us/sample - loss: 0.3293 - acc: 0.8737 - val_loss: 0.3391 - val_acc: 0.8739\n",
      "Epoch 33/100\n",
      "9864/9864 [==============================] - 2s 199us/sample - loss: 0.3190 - acc: 0.8796 - val_loss: 0.3535 - val_acc: 0.8670\n",
      "Epoch 34/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.3015 - acc: 0.8857 - val_loss: 0.3365 - val_acc: 0.8768\n",
      "Epoch 35/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.3039 - acc: 0.8856 - val_loss: 0.3297 - val_acc: 0.8824\n",
      "Epoch 36/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.2926 - acc: 0.8867 - val_loss: 0.3287 - val_acc: 0.8824\n",
      "Epoch 37/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.2896 - acc: 0.8906 - val_loss: 0.3181 - val_acc: 0.8824\n",
      "Epoch 38/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.2889 - acc: 0.8867 - val_loss: 0.3271 - val_acc: 0.8820\n",
      "Epoch 39/100\n",
      "9864/9864 [==============================] - 2s 202us/sample - loss: 0.2808 - acc: 0.8924 - val_loss: 0.3191 - val_acc: 0.8816\n",
      "Epoch 40/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.2713 - acc: 0.8980 - val_loss: 0.3104 - val_acc: 0.8824\n",
      "Epoch 41/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.2651 - acc: 0.8988 - val_loss: 0.2955 - val_acc: 0.8910\n",
      "Epoch 42/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.2753 - acc: 0.8944 - val_loss: 0.3119 - val_acc: 0.8930\n",
      "Epoch 43/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.2549 - acc: 0.9048 - val_loss: 0.2986 - val_acc: 0.8889\n",
      "Epoch 44/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.2486 - acc: 0.9056 - val_loss: 0.2887 - val_acc: 0.8954\n",
      "Epoch 45/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.2487 - acc: 0.9050 - val_loss: 0.2980 - val_acc: 0.8950\n",
      "Epoch 46/100\n",
      "9864/9864 [==============================] - 2s 202us/sample - loss: 0.2416 - acc: 0.9077 - val_loss: 0.2940 - val_acc: 0.8950\n",
      "Epoch 47/100\n",
      "9864/9864 [==============================] - 2s 207us/sample - loss: 0.2444 - acc: 0.9079 - val_loss: 0.3136 - val_acc: 0.9003\n",
      "Epoch 48/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.2344 - acc: 0.9106 - val_loss: 0.2996 - val_acc: 0.8938\n",
      "Epoch 49/100\n",
      "9864/9864 [==============================] - 2s 206us/sample - loss: 0.2270 - acc: 0.9115 - val_loss: 0.3064 - val_acc: 0.8970\n",
      "Epoch 50/100\n",
      "9864/9864 [==============================] - 2s 204us/sample - loss: 0.2310 - acc: 0.9121 - val_loss: 0.3199 - val_acc: 0.8901\n",
      "Epoch 51/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.2369 - acc: 0.9084 - val_loss: 0.2988 - val_acc: 0.8962\n",
      "Epoch 52/100\n",
      "9864/9864 [==============================] - 2s 200us/sample - loss: 0.2213 - acc: 0.9150 - val_loss: 0.3141 - val_acc: 0.8934\n",
      "Epoch 53/100\n",
      "9864/9864 [==============================] - 2s 201us/sample - loss: 0.2210 - acc: 0.9176 - val_loss: 0.3099 - val_acc: 0.8942\n",
      "Epoch 54/100\n",
      "9864/9864 [==============================] - 2s 203us/sample - loss: 0.2088 - acc: 0.9218 - val_loss: 0.3133 - val_acc: 0.8934\n",
      "Best:  [0.22333738, 0.36394972, 0.45316303, 0.5975264, 0.6522709, 0.6944444, 0.72404706, 0.74006486, 0.7561841, 0.7719992, 0.7887267, 0.78649634, 0.7906529, 0.8007907, 0.81042176, 0.8193431, 0.82512164, 0.83748984, 0.82978505, 0.84195054, 0.83738846, 0.8440795, 0.8531022, 0.84945256, 0.8562449, 0.8626318, 0.85847527, 0.8639497, 0.87570965, 0.87672347, 0.8778386, 0.8736821, 0.879562, 0.8857461, 0.8856448, 0.88665855, 0.8906123, 0.88665855, 0.89243716, 0.898013, 0.89882404, 0.89436334, 0.90480536, 0.9056164, 0.90500814, 0.90774536, 0.9079481, 0.9105839, 0.91149634, 0.9121046, 0.9083536, 0.9150446, 0.91757905, 0.921837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new data result :\n",
      "[answer]  -->  [predict err]\n",
      "fo_drive  -->  fo_short         err_index number :  9\n",
      "fo_drive  -->  fo_smash         err_index number :  11\n",
      "fo_drive  -->  fo_short         err_index number :  12\n",
      "back_smash  -->  fo_smash         err_index number :  73\n",
      "back_smash  -->  back_drive         err_index number :  74\n",
      "back_smash  -->  back_drive         err_index number :  81\n",
      "back_smash  -->  fo_short         err_index number :  84\n",
      "hit:  80  miss :  7 percent :  91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "target_folder = 'swing'\n",
    "mode = 'X_acc_analysis model'\n",
    "\n",
    "print('this model is ',mode,'\\n\\n')\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk(target_folder):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "print('load_file_complete')\n",
    "print('make DataFrame...')\n",
    "total_data = []\n",
    "total_label = []\n",
    "\n",
    "for z in tqdm(filename_in_dir):\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(((df['AX'][i]/1000)**2 + (df['AY'][i]/1000)**2 + (df['AZ'][i]/1000)**2)**0.5 )\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    total_data.append(tmp_li)\n",
    "    total_label.append(label)\n",
    "    \n",
    "print('make DataFrame complete ....')\n",
    "\n",
    "print('label_encoding processing...')\n",
    "encoder = LabelEncoder()\n",
    "arr_label = encoder.fit_transform(total_label)\n",
    "\n",
    "total_data = np.array(total_data)\n",
    "arr_label = np.array(arr_label)\n",
    "print('Done....')\n",
    "print(len(arr_label))\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(total_data,arr_label,test_size=0.2,random_state=0)\n",
    "\n",
    "nsamples, nx, ny = x_train.shape\n",
    "d2_train_dataset = x_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = x_test.shape\n",
    "d2_test_dataset = x_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "session = tf.Session(config=config)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential() # Sequeatial Model \n",
    "    model.add(LSTM(120, input_shape=(60,1),return_sequences = True)) # (timestep, feature) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv1D(256,\n",
    "                     1,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=3))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(LSTM(256,dropout=0.2, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    # 3. 모델 학습과정 설정하기\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=100, batch_size=256,callbacks=[earlystopping] ,validation_data=(x_test, y_test))\n",
    "    model.save('model_x.h5')\n",
    "    model.save_weights('model_x_weights.h5')\n",
    "print(\"Best: \" ,(hist.history['acc']))\n",
    "\n",
    "filename_in_dir = []\n",
    "\n",
    "for root, dirs, files in os.walk('test_data/'):\n",
    "    for  fname in files:\n",
    "        full_fname = os.path.join(root, fname)\n",
    "        filename_in_dir.append(full_fname)\n",
    "\n",
    "s_total_data = []\n",
    "s_total_label = []\n",
    "\n",
    "for z in filename_in_dir:\n",
    "    sp = z.split('/')\n",
    "    label = sp[1]\n",
    "    f = open(z,'r')\n",
    "    d = f.read()\n",
    "    data = d.split('\\n')\n",
    "    data.pop(0)\n",
    "    index = data.pop(0)\n",
    "    real_data = []\n",
    "    for y in range(len(data)):\n",
    "        if data[y]=='':\n",
    "            continue\n",
    "        real_data.append(data[y].split(','))\n",
    "    df = pd.DataFrame(real_data)\n",
    "    index_li = index.split(',')\n",
    "    df.columns = index_li\n",
    "    for y in index_li:\n",
    "        df[y] = pd.to_numeric(df[y],downcast='float')\n",
    "    tmp_li = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=[]\n",
    "        tmp.append(((df['AX'][i]/1000)**2 + (df['AY'][i]/1000)**2 + (df['AZ'][i]/1000)**2)**0.5 )\n",
    "        tmp_li.append(tmp)\n",
    "    \n",
    "    s_total_data.append(tmp_li)\n",
    "    s_total_label.append(label)\n",
    "    \n",
    "s_total_data = np.array(s_total_data)\n",
    "nsamples, nx, ny = s_total_data.shape\n",
    "#sample = total_data.reshape((nsamples,nx*ny))\n",
    "\n",
    "sample_pred = model.predict(s_total_data)\n",
    "sample_pred = np.argmax(sample_pred,axis=-1)\n",
    "lab = encoder.inverse_transform(sample_pred)\n",
    "\n",
    "hit = 0\n",
    "miss = 0\n",
    "answer=[]\n",
    "print('testing new data result :\\n[answer]  -->  [predict err]')\n",
    "for x in range(len(lab)):\n",
    "    if lab[x] == s_total_label[x]:\n",
    "        hit+=1\n",
    "        answer.append(lab[x])\n",
    "    else:\n",
    "        miss+=1\n",
    "        print(s_total_label[x],' --> ' ,lab[x],'        err_index number : ',x)\n",
    "\n",
    "        \n",
    "print('hit: ',hit,' miss : ',miss,'percent : ',(100*hit)/(hit+miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
